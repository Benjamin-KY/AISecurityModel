# ğŸ›¡ï¸ AI Security & Jailbreak Defence Course

A comprehensive 15-notebook educational course for teaching AI security, jailbreak techniques, and defence strategies through hands-on experience with intentionally vulnerable models.

## ğŸ‡¦ğŸ‡º Made for Australian Learners

This project uses Australian English orthography throughout and incorporates Australian compliance requirements (Privacy Act 1988, ACSC Essential Eight, APRA CPS 234, etc.).

## âš ï¸ Important Disclaimer

**This course includes intentionally vulnerable models designed exclusively for educational purposes.**

- âœ… Use for authorised education and training
- âœ… Use for security research in controlled environments
- âœ… Use for CTF challenges and approved competitions
- âŒ **DO NOT** deploy vulnerable models in production
- âŒ **DO NOT** use on real systems without authorisation
- âŒ **DO NOT** use for malicious purposes

---

## ğŸ“š Complete Course Curriculum (15 Notebooks)

### ğŸŸ¢ Beginner Track (Notebooks 1-4)

#### Notebook 1: Introduction & Your First Jailbreak
**Duration**: 30-45 minutes | **Difficulty**: Beginner
- What is a jailbreak?
- Execute your first successful jailbreak
- Understand the vulnerable-then-educate pattern
- Australian Privacy Act 1988 context

#### Notebook 2: Basic Jailbreak Techniques
**Duration**: 45-60 minutes | **Difficulty**: Beginner
- Role-playing attacks (DAN variants)
- Multi-turn conversation exploits
- Social engineering techniques
- Measuring attack success rates

#### Notebook 3: Intermediate Attacks (Encoding & Crescendo)
**Duration**: 60 minutes | **Difficulty**: Intermediate
- Encoding-based bypasses (Base64, ROT13, Hex)
- Crescendo attacks (gradual escalation)
- Multi-step exploitation chains
- Detection and prevention strategies

#### Notebook 4: Advanced Jailbreaks (Skeleton Key)
**Duration**: 60-75 minutes | **Difficulty**: Advanced
- Skeleton Key attack (Microsoft's vulnerability)
- System prompt extraction techniques
- Advanced prompt injection patterns
- Real-world case studies

---

### ğŸŸ¡ Intermediate Track (Notebooks 5-9)

#### Notebook 5: XAI & Interpretability (Inside the Model)
**Duration**: 75 minutes | **Difficulty**: Intermediate
- Attention visualization and analysis
- Activation pattern examination
- Sparse Autoencoders (SAE) for interpretability
- Understanding why jailbreaks work

#### Notebook 6: Defence & Real-World Application
**Duration**: 90 minutes | **Difficulty**: Intermediate
- 7-layer defence-in-depth architecture
- Input validation and sanitization
- Output filtering and content moderation
- Australian compliance integration (ACSC Essential Eight)

#### Notebook 7: Automated Red Teaming & Testing
**Duration**: 90 minutes | **Difficulty**: Advanced
- Build automated attack testing frameworks
- 10+ attack templates across 6 categories
- CI/CD integration for continuous testing
- Measuring ASR (Attack Success Rate)

#### Notebook 8: Prompt Engineering for Safety
**Duration**: 75 minutes | **Difficulty**: Intermediate
- 10 prompt hardening techniques
- System prompt design patterns
- Industry-specific templates (Healthcare, Finance, Gov, Retail)
- A/B testing for effectiveness measurement

#### Notebook 9: Real-time Monitoring Dashboard
**Duration**: 75 minutes | **Difficulty**: Intermediate
- Build Streamlit security dashboard
- Real-time attack detection
- SIEM integration (Splunk, ELK)
- Alert system implementation

---

### ğŸ”´ Advanced Track (Notebooks 10-15)

#### Notebook 10: CTF Security Challenges
**Duration**: 120 minutes | **Difficulty**: Advanced
- 15 complete CTF challenges (Beginner â†’ Advanced)
- 500 points total across 5 difficulty tiers
- Automated scoring system with 5 rank levels
- Certificate generation upon completion

#### Notebook 11: Industry-Specific AI Security
**Duration**: 90 minutes | **Difficulty**: Intermediate
- **Healthcare**: TGA, PBS, medical records (patient safety)
- **Financial**: APRA CPS 234, ASIC, AML/CTF ($10k threshold)
- **Government**: PSPF, ISM, security clearances, classifications
- **Retail**: CDR, PCI DSS, customer authentication
- Cross-sector compliance comparison

#### Notebook 12: Fine-tuning for Robustness
**Duration**: 120 minutes | **Difficulty**: Advanced
- Adversarial training dataset creation
- LoRA (Low-Rank Adaptation) implementation
- Complete training pipeline (SFT â†’ RLHF)
- Robustness evaluation (45% â†’ 4.8% ASR improvement)
- Safety reward model for alignment

#### Notebook 13: Multi-modal AI Security
**Duration**: 100 minutes | **Difficulty**: Advanced
- Vision-language model (VLM) security
- OCR-based prompt injection detection
- Adversarial image detection
- Cross-modal attack defense
- Deepfake detection techniques

#### Notebook 14: AI Supply Chain Security
**Duration**: 90 minutes | **Difficulty**: Advanced
- Model provenance verification
- Data poisoning detection
- Model watermarking for authenticity
- AI-SBOM (Software Bill of Materials) generation
- Secure model registry implementation

#### Notebook 15: Incident Response & Forensics
**Duration**: 100 minutes | **Difficulty**: Advanced
- Real-time incident detection systems
- Incident response playbooks
- Forensic analysis and attack timeline reconstruction
- MTTD/MTTR metrics tracking
- Australian NDB (Notifiable Data Breaches) compliance
- OAIC notification requirements (30-day deadline)

---

## ğŸ¯ Learning Outcomes

Upon completing all 15 notebooks, students will be able to:

### Technical Skills
1. âœ… Execute and defend against 20+ jailbreak techniques
2. âœ… Build complete 7-layer defence systems
3. âœ… Implement automated red teaming frameworks
4. âœ… Fine-tune models for robustness (LoRA + RLHF)
5. âœ… Secure multi-modal AI systems
6. âœ… Conduct forensic analysis of AI security incidents

### Compliance & Governance
7. âœ… Apply Australian Privacy Act 1988 requirements
8. âœ… Implement sector-specific compliance (APRA, TGA, PSPF)
9. âœ… Generate AI-SBOM for supply chain security
10. âœ… Execute NDB breach notification procedures

### Strategic Understanding
11. âœ… Assess AI security risk across industries
12. âœ… Design defense-in-depth architectures
13. âœ… Measure security effectiveness (ASR, MTTD, MTTR)
14. âœ… Conduct post-incident lessons learned

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- GPU recommended (notebooks work on CPU but slower)
- Basic Python and ML knowledge

### Installation

```bash
# Clone repository
git clone https://github.com/Benjamin-KY/AISecurityModel.git
cd AISecurityModel

# Install dependencies
pip install transformers torch accelerate peft bitsandbytes
pip install streamlit pandas numpy matplotlib seaborn

# Start with Notebook 1
jupyter notebook notebooks/01_Introduction_First_Jailbreak.ipynb
```

### Course Paths

**ğŸƒ Fast Track (4-6 hours)**
Notebooks: 1 â†’ 2 â†’ 4 â†’ 6 â†’ 10

**ğŸ“š Standard Track (15-20 hours)**
All notebooks 1-15 in sequence

**ğŸ“ Deep Dive (30-40 hours)**
All notebooks + exercises + CTF challenges + assessments

---

## ğŸ“ Project Structure

```
AISecurityModel/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Introduction_First_Jailbreak.ipynb
â”‚   â”œâ”€â”€ 02_Basic_Jailbreak_Techniques.ipynb
â”‚   â”œâ”€â”€ 03_Intermediate_Attacks_Encoding_Crescendo.ipynb
â”‚   â”œâ”€â”€ 04_Advanced_Jailbreaks_Skeleton_Key.ipynb
â”‚   â”œâ”€â”€ 05_XAI_Interpretability_Inside_Model.ipynb
â”‚   â”œâ”€â”€ 06_Defence_Real_World_Application.ipynb
â”‚   â”œâ”€â”€ 07_Automated_Red_Teaming_Testing.ipynb
â”‚   â”œâ”€â”€ 08_Prompt_Engineering_Safety.ipynb
â”‚   â”œâ”€â”€ 09_Realtime_Monitoring_Dashboard.ipynb
â”‚   â”œâ”€â”€ 10_CTF_Security_Challenges.ipynb
â”‚   â”œâ”€â”€ 11_Industry_Specific_Security.ipynb
â”‚   â”œâ”€â”€ 12_Fine_Tuning_Robustness.ipynb
â”‚   â”œâ”€â”€ 13_Multi_Modal_Security.ipynb
â”‚   â”œâ”€â”€ 14_AI_Supply_Chain_Security.ipynb
â”‚   â””â”€â”€ 15_Incident_Response_Forensics.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vulnerability_taxonomy.json
â”‚   â””â”€â”€ training_data.jsonl
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_training_data.py
â”‚   â”œâ”€â”€ finetune_model_v2.py
â”‚   â””â”€â”€ test_model.py
â””â”€â”€ README.md
```

---

## ğŸ”“ Vulnerability Categories Covered

### Attack Techniques (20+)
- Prompt injection (direct, indirect, multi-turn)
- Role-playing attacks (DAN 6.0, 11.0, Jailbreak)
- Encoding bypasses (Base64, ROT13, Hex, Unicode)
- Crescendo attacks (gradual escalation)
- Skeleton Key (Microsoft vulnerability)
- System prompt extraction
- Context manipulation
- Social engineering
- OCR prompt injection
- Cross-modal attacks
- Data poisoning
- Model backdoors

### Defence Mechanisms
- 7-layer defence-in-depth
- Input validation & sanitization
- Output filtering & content moderation
- Prompt hardening (10 techniques)
- Real-time monitoring
- Automated testing
- Adversarial training
- Model watermarking
- Incident response

---

## ğŸ‡¦ğŸ‡º Australian Compliance Coverage

### Legislation & Frameworks
- **Privacy Act 1988**: Personal information protection, NDB scheme
- **ACSC Essential Eight**: Cyber security baseline
- **APRA CPS 234**: Financial services information security
- **PSPF**: Protective Security Policy Framework (government)
- **ISM**: Information Security Manual (ASD)
- **TGA**: Therapeutic Goods Administration (healthcare)
- **ASIC**: Financial advice regulations
- **AUSTRAC**: AML/CTF compliance

### Sector-Specific Requirements
- **Healthcare**: Medical device regulation, patient safety
- **Financial**: 72-hour breach reporting, AML/CTF $10k threshold
- **Government**: Security clearances, classified information
- **Retail**: Consumer Data Right (CDR), PCI DSS

---

## ğŸ“Š Course Metrics

- **Total Notebooks**: 15
- **Total Duration**: ~18-22 hours
- **Exercises**: 50+ hands-on activities
- **CTF Challenges**: 15 complete challenges
- **Code Examples**: 100+ production-ready implementations
- **Assessment Questions**: 30+ knowledge checks

---

## ğŸ› ï¸ Technical Stack

### Models
- **Base**: Qwen2.5-3B-Instruct (and variants)
- **Fine-tuning**: LoRA (Low-Rank Adaptation)
- **Quantization**: 4-bit (BitsAndBytes)
- **Size**: 3B parameters, ~2GB memory

### Libraries
- **transformers**: HuggingFace model loading
- **peft**: LoRA fine-tuning
- **torch**: Deep learning framework
- **streamlit**: Dashboard creation
- **pandas/numpy**: Data analysis
- **matplotlib/seaborn**: Visualization

---

## ğŸ“ For Educators

### Course Formats

**ğŸ¯ Workshop (4-6 hours)**
- Notebooks 1, 2, 4, 6
- Focus on core attack/defence concepts
- Hands-on exercises only

**ğŸ“š University Course (12-15 weeks)**
- All 15 notebooks
- 1 notebook per week
- Assignments and assessments
- Final CTF competition

**ğŸ’¼ Corporate Training (3 days)**
- Day 1: Notebooks 1-6 (Attacks & Defence)
- Day 2: Notebooks 7-11 (Advanced & Industry-Specific)
- Day 3: Notebooks 12-15 (Production Hardening)

### Assessment Options
- Quiz questions (included in notebooks)
- CTF challenge completion (Notebook 10)
- Build custom defence system (project)
- Incident response drill (tabletop exercise)

---

## ğŸ“š Additional Resources

### Recommended Reading
- [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [MITRE ATLAS](https://atlas.mitre.org/) - AI threat framework
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
- [Australian Cyber Security Centre](https://www.cyber.gov.au/)
- [OAIC Privacy Guidelines](https://www.oaic.gov.au/privacy)

### Related Tools
- **LLM Guard**: Open-source security toolkit
- **Garak**: LLM vulnerability scanner
- **PromptInject**: Research benchmark
- **CleverHans**: Adversarial examples library

### Research Papers
- "Jailbroken: How Does LLM Safety Break Down?" (Wei et al.)
- "Universal and Transferable Adversarial Attacks" (Wallace et al.)
- "Constitutional AI" (Anthropic)
- "Red Teaming Language Models" (Perez et al.)

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:
- Additional training examples
- New attack techniques
- Industry-specific case studies
- Compliance updates (regulatory changes)
- Translation to other languages
- Curriculum enhancements

---

## ğŸ“„ License

**Code & Models**: Apache 2.0
**Educational Materials**: CC BY-SA 4.0
**Documentation**: CC BY 4.0

---

## âš–ï¸ Ethics & Responsible Use

### Code of Conduct

All users must:
1. âœ… Use only in authorised educational/research contexts
2. âœ… Practice responsible disclosure of vulnerabilities
3. âœ… Respect privacy and data protection laws
4. âœ… Follow institutional ethics guidelines
5. âŒ Never attack production systems without permission
6. âŒ Never use techniques for malicious purposes

### For Institutions

Ensure you:
- Have ethics approval for security education
- Provide supervised learning environments
- Require signed code of conduct from students
- Implement proper safeguards and monitoring
- Comply with local regulations

---

## ğŸ“§ Contact & Support

- **GitHub Issues**: For bug reports and feature requests
- **Discussions**: For questions and community support
- **Security**: For responsible disclosure of vulnerabilities

---

## ğŸ™ Acknowledgements

- **Qwen Team** (Alibaba Cloud) for base models
- **HuggingFace** for transformers library
- **PEFT Team** for LoRA implementation
- **Australian AI security community**
- **OWASP, MITRE, NIST** for frameworks

---

## ğŸ“ Citation

```bibtex
@software{ai_security_jailbreak_defence_course,
  title = {AI Security & Jailbreak Defence: A Comprehensive 15-Notebook Course},
  author = {Benjamin-KY},
  year = {2025},
  url = {https://github.com/Benjamin-KY/AISecurityModel},
  note = {Educational course for AI security training with Australian compliance focus}
}
```

---

**Version**: 2.0
**Last Updated**: 2025-11-05
**Status**: Complete (15/15 notebooks) - Ready for deployment
**Course Completion**: All notebooks implemented and tested

**Remember**: This is a tool for learning. Use responsibly, teach responsibly, and build safer AI systems! ğŸ›¡ï¸

